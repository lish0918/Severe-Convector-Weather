{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0b4d40",
   "metadata": {},
   "source": [
    "# Imbalanced-learn for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae4c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,log_loss,auc,plot_confusion_matrix\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, label_binarize, OneHotEncoder, LabelEncoder)\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from itertools import cycle, product\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379b367",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61508902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_excel('../Case.xlsx',sheet_name='initial')\n",
    "data=dataset.values\n",
    "\n",
    "array=[]\n",
    "for i in data:\n",
    "    if i[0]==8:\n",
    "        array.append(list(i))\n",
    "    data=np.array(array)\n",
    "    \n",
    "X =data[:,1:18] #1:18\n",
    "Y =data[:,19]\n",
    "seed = random.randint(0,1000)\n",
    "#seed = 638\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "dict_resample = {}\n",
    "dict_model = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073b003",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362be73c",
   "metadata": {},
   "source": [
    "### RandomOverSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f88e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 106)]\n"
     ]
    }
   ],
   "source": [
    "# 简单的复制样本\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled ,y_resampled= ros.fit_resample(X_train,y_train)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['RandomOverSampler'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2431478",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de7a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 106)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTE'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b00bd",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1869ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 109)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['ADASYN'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2156d3",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3803a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 106)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-1').fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['BorderlineSMOTE-1'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa17fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 106)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-2').fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['BorderlineSMOTE-2'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f6d5b",
   "metadata": {},
   "source": [
    "## Over- and under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c2204",
   "metadata": {},
   "source": [
    "### SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548fe8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 34), (1.0, 58)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTEENN'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7ca24",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0246f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 96), (1.0, 96)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTETomek'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886163f2",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8263f",
   "metadata": {},
   "source": [
    "使用训练数据的不同随机子集来训练每个 Base Model，最后每个 Base Model 权重相同，分类问题进行投票，回归问题平均。\n",
    "\n",
    "随机森林就用到了Bagging，并且具有天然的并行性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4174384",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cde4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 27)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['Bagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1cafe",
   "metadata": {},
   "source": [
    "### BalancedBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83acd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 27)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['BalancedBagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0eccc9",
   "metadata": {},
   "source": [
    "### BalancedRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb391d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 27)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['BalancedRandomForest'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d877f",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570aace",
   "metadata": {},
   "source": [
    "Boosting是一种迭代的方法，每一次训练会更关心上一次被分错的样本，比如改变被错分的样本的权重的Adaboost方法。还有许多都是基于这种思想，比如Gradient Boosting等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228148fa",
   "metadata": {},
   "source": [
    "### RUSBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffac187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 27)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['RUSBoost'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99521d",
   "metadata": {},
   "source": [
    "### EasyEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c97941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 106), (1.0, 27)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['EasyEnsemble'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26088094",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2c2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f949665d8efb449eb567f02fd2ef2be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "################### train #####################################\n",
    "scores={}\n",
    "cm = []\n",
    "auc = []\n",
    "for name, (X, y) in tqdm_notebook(list(dict_model.items())):\n",
    "    if name in ['Bagging']:\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                random_state=0)\n",
    "    elif name in ['BalancedBagging']:\n",
    "        from imblearn.ensemble import BalancedBaggingClassifier\n",
    "        clf = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        sampling_strategy='auto',\n",
    "                                        replacement=False,\n",
    "                                        random_state=0)\n",
    "    elif name in ['BalancedRandomForest']:\n",
    "        from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "        clf = BalancedRandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    elif name in ['RUSBoost']:\n",
    "        from imblearn.ensemble import RUSBoostClassifier\n",
    "        clf = RUSBoostClassifier(random_state=0)\n",
    "    elif name in ['EasyEnsemble']:\n",
    "        from imblearn.ensemble import EasyEnsembleClassifier\n",
    "        clf = EasyEnsembleClassifier(random_state=0)\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "\n",
    "    # 混淆矩阵\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append((name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e4fb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f369255392f340babc94d9c3c854b7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    RANDOM_STATE = 2019\n",
    "    clf = RandomForestClassifier(n_estimators=161,\n",
    "                                     max_depth=49,\n",
    "                                     max_features=\"sqrt\",\n",
    "                                     random_state=RANDOM_STATE)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('RF'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c396138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd09f609be824072bca4d830e8a53555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    clf = LogisticRegression(penalty=\"l2\",solver=\"liblinear\",C=0.8,max_iter=1000)\n",
    "       \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('LR'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e5dd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27b498f24dc4ca7bd240e33e3f67b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    clf = AdaBoostClassifier(n_estimators=161,\n",
    "                             learning_rate=0.5,\n",
    "                                     random_state=RANDOM_STATE)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('AdaBoost'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4480a576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771\n",
      "0.658\n",
      "0.619\n",
      "0.655\n",
      "0.530\n",
      "0.577\n",
      "0.631\n",
      "0.634\n",
      "0.557\n",
      "0.562\n",
      "0.631\n",
      "0.708\n",
      "0.714\n",
      "0.750\n",
      "0.768\n",
      "0.708\n",
      "0.685\n",
      "0.738\n",
      "0.667\n",
      "0.696\n",
      "0.649\n",
      "0.655\n",
      "0.631\n",
      "0.577\n",
      "0.726\n"
     ]
    }
   ],
   "source": [
    "for i in auc[1:]:\n",
    "    print(\"{:.3f}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "382d0784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.308\n",
      "0.200\n",
      "0.000\n",
      "0.182\n",
      "0.154\n",
      "0.235\n",
      "0.286\n",
      "0.286\n",
      "0.158\n",
      "0.125\n",
      "0.250\n",
      "0.222\n",
      "0.235\n",
      "0.267\n",
      "0.286\n",
      "0.235\n",
      "0.217\n",
      "0.235\n",
      "0.182\n",
      "0.235\n",
      "0.133\n",
      "0.188\n",
      "0.250\n",
      "0.217\n",
      "0.333\n"
     ]
    }
   ],
   "source": [
    "for name,c in cm[1:]:\n",
    "    print(\"{:.3f}\".format(c[1][1]/(c[1][1]+c[0][1]+c[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caf142c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n"
     ]
    }
   ],
   "source": [
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59284b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "BalancedBagging\n",
      "BalancedRandomForest\n",
      "RUSBoost\n",
      "EasyEnsemble\n",
      "RFRandomOverSampler\n",
      "RFSMOTE\n",
      "RFADASYN\n",
      "RFBorderlineSMOTE-1\n",
      "RFBorderlineSMOTE-2\n",
      "RFSMOTEENN\n",
      "RFSMOTETomek\n",
      "LRRandomOverSampler\n",
      "LRSMOTE\n",
      "LRADASYN\n",
      "LRBorderlineSMOTE-1\n",
      "LRBorderlineSMOTE-2\n",
      "LRSMOTEENN\n",
      "LRSMOTETomek\n",
      "AdaBoostRandomOverSampler\n",
      "AdaBoostSMOTE\n",
      "AdaBoostADASYN\n",
      "AdaBoostBorderlineSMOTE-1\n",
      "AdaBoostBorderlineSMOTE-2\n",
      "AdaBoostSMOTEENN\n",
      "AdaBoostSMOTETomek\n"
     ]
    }
   ],
   "source": [
    "for name,c in cm:\n",
    "    print(\"{:}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "691a6a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    28\n",
       "1.0     6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = pd.Series(y_test) \n",
    "ytest.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
