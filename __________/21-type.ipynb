{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0b4d40",
   "metadata": {},
   "source": [
    "# Imbalanced-learn for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae4c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,log_loss,auc,plot_confusion_matrix\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, label_binarize, OneHotEncoder, LabelEncoder)\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import cycle, product\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379b367",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61508902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_excel('../Case.xlsx',sheet_name='initial')\n",
    "data=dataset.values\n",
    "\n",
    "#array=[]\n",
    "#for i in data:\n",
    "#    if i[0]==2:\n",
    "#        array.append(list(i))\n",
    "#    data=np.array(array)\n",
    "    \n",
    "X =data[:,1:18]\n",
    "Y =data[:,19]\n",
    "seed = random.randint(0,1000)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "dict_resample = {}\n",
    "dict_model = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073b003",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362be73c",
   "metadata": {},
   "source": [
    "### RandomOverSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f88e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 1795)]\n"
     ]
    }
   ],
   "source": [
    "# 简单的复制样本\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled ,y_resampled= ros.fit_resample(X_train,y_train)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['RandomOverSampler'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2431478",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de7a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 1795)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTE'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b00bd",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1869ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 1756)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['ADASYN'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2156d3",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3803a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 1795)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-1').fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['BorderlineSMOTE-1'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa17fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 1794)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-2').fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['BorderlineSMOTE-2'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f6d5b",
   "metadata": {},
   "source": [
    "## Over- and under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c2204",
   "metadata": {},
   "source": [
    "### SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548fe8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1097), (1.0, 1614)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTEENN'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7ca24",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0246f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1760), (1.0, 1760)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "dict_resample['SMOTETomek'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886163f2",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8263f",
   "metadata": {},
   "source": [
    "使用训练数据的不同随机子集来训练每个 Base Model，最后每个 Base Model 权重相同，分类问题进行投票，回归问题平均。\n",
    "\n",
    "随机森林就用到了Bagging，并且具有天然的并行性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4174384",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cde4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 157)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['Bagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1cafe",
   "metadata": {},
   "source": [
    "### BalancedBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83acd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 157)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['BalancedBagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0eccc9",
   "metadata": {},
   "source": [
    "### BalancedRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb391d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 157)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['BalancedRandomForest'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d877f",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570aace",
   "metadata": {},
   "source": [
    "Boosting是一种迭代的方法，每一次训练会更关心上一次被分错的样本，比如改变被错分的样本的权重的Adaboost方法。还有许多都是基于这种思想，比如Gradient Boosting等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228148fa",
   "metadata": {},
   "source": [
    "### RUSBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffac187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 157)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['RUSBoost'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99521d",
   "metadata": {},
   "source": [
    "### EasyEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c97941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 1795), (1.0, 157)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "dict_model['EasyEnsemble'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26088094",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2c2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901912b5b6da4376bdab703b9c8c731a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "################### train #####################################\n",
    "scores={}\n",
    "cm = []\n",
    "auc = []\n",
    "for name, (X, y) in tqdm_notebook(list(dict_model.items())):\n",
    "    if name in ['Bagging']:\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                random_state=0)\n",
    "    elif name in ['BalancedBagging']:\n",
    "        from imblearn.ensemble import BalancedBaggingClassifier\n",
    "        clf = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        sampling_strategy='auto',\n",
    "                                        replacement=False,\n",
    "                                        random_state=0)\n",
    "    elif name in ['BalancedRandomForest']:\n",
    "        from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "        clf = BalancedRandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    elif name in ['RUSBoost']:\n",
    "        from imblearn.ensemble import RUSBoostClassifier\n",
    "        clf = RUSBoostClassifier(random_state=0)\n",
    "    elif name in ['EasyEnsemble']:\n",
    "        from imblearn.ensemble import EasyEnsembleClassifier\n",
    "        clf = EasyEnsembleClassifier(random_state=0)\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "\n",
    "    # 混淆矩阵\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append((name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e4fb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f64a819f90547099569aac3a740f131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    RANDOM_STATE = 2019\n",
    "    clf = RandomForestClassifier(n_estimators=161,\n",
    "                                     max_depth=49,\n",
    "                                     max_features=\"sqrt\",\n",
    "                                     random_state=RANDOM_STATE)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('RF'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c396138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7534e2d7c617432282fc27345304b0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    clf = LogisticRegression(penalty=\"l2\",solver=\"liblinear\",C=0.8,max_iter=1000)\n",
    "       \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('LR'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e5dd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273d939015204fa2a629681afdc786bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, (X, y) in tqdm_notebook(list(dict_resample.items())):\n",
    "    clf = AdaBoostClassifier(n_estimators=161,\n",
    "                             learning_rate=0.5,\n",
    "                                     random_state=RANDOM_STATE)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append(('AdaBoost'+name, cnf_matrix))\n",
    "    # ROC\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_test, y_test_score[:,1])\n",
    "    auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4480a576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n",
      "0.774\n",
      "0.813\n",
      "0.771\n",
      "0.766\n",
      "0.792\n",
      "0.798\n",
      "0.801\n",
      "0.803\n",
      "0.782\n",
      "0.774\n",
      "0.797\n",
      "0.834\n",
      "0.829\n",
      "0.830\n",
      "0.830\n",
      "0.823\n",
      "0.830\n",
      "0.834\n",
      "0.801\n",
      "0.776\n",
      "0.784\n",
      "0.766\n",
      "0.764\n",
      "0.779\n",
      "0.782\n"
     ]
    }
   ],
   "source": [
    "for i in auc:\n",
    "    print(\"{:.3f}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "382d0784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056\n",
      "0.167\n",
      "0.149\n",
      "0.155\n",
      "0.140\n",
      "0.111\n",
      "0.198\n",
      "0.187\n",
      "0.163\n",
      "0.158\n",
      "0.163\n",
      "0.187\n",
      "0.175\n",
      "0.175\n",
      "0.180\n",
      "0.191\n",
      "0.161\n",
      "0.144\n",
      "0.179\n",
      "0.187\n",
      "0.159\n",
      "0.161\n",
      "0.157\n",
      "0.156\n",
      "0.141\n",
      "0.152\n"
     ]
    }
   ],
   "source": [
    "for name,c in cm:\n",
    "    print(\"{:.3f}\".format(c[1][1]/(c[1][1]+c[0][1]+c[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2163f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "BalancedBagging\n",
      "BalancedRandomForest\n",
      "RUSBoost\n",
      "EasyEnsemble\n",
      "RFRandomOverSampler\n",
      "RFSMOTE\n",
      "RFADASYN\n",
      "RFBorderlineSMOTE-1\n",
      "RFBorderlineSMOTE-2\n",
      "RFSMOTEENN\n",
      "RFSMOTETomek\n",
      "LRRandomOverSampler\n",
      "LRSMOTE\n",
      "LRADASYN\n",
      "LRBorderlineSMOTE-1\n",
      "LRBorderlineSMOTE-2\n",
      "LRSMOTEENN\n",
      "LRSMOTETomek\n",
      "AdaBoostRandomOverSampler\n",
      "AdaBoostSMOTE\n",
      "AdaBoostADASYN\n",
      "AdaBoostBorderlineSMOTE-1\n",
      "AdaBoostBorderlineSMOTE-2\n",
      "AdaBoostSMOTEENN\n",
      "AdaBoostSMOTETomek\n"
     ]
    }
   ],
   "source": [
    "for name,c in cm:\n",
    "    print(\"{:}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20dfb134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging: 0.056\n",
      "BalancedBagging: 0.167\n",
      "BalancedRandomForest: 0.149\n",
      "RUSBoost: 0.155\n",
      "EasyEnsemble: 0.140\n",
      "RFRandomOverSampler: 0.111\n",
      "RFSMOTE: 0.198\n",
      "RFADASYN: 0.187\n",
      "RFBorderlineSMOTE-1: 0.163\n",
      "RFBorderlineSMOTE-2: 0.158\n",
      "RFSMOTEENN: 0.163\n",
      "RFSMOTETomek: 0.187\n",
      "LRRandomOverSampler: 0.175\n",
      "LRSMOTE: 0.175\n",
      "LRADASYN: 0.180\n",
      "LRBorderlineSMOTE-1: 0.191\n",
      "LRBorderlineSMOTE-2: 0.161\n",
      "LRSMOTEENN: 0.144\n",
      "LRSMOTETomek: 0.179\n",
      "AdaBoostRandomOverSampler: 0.187\n",
      "AdaBoostSMOTE: 0.159\n",
      "AdaBoostADASYN: 0.161\n",
      "AdaBoostBorderlineSMOTE-1: 0.157\n",
      "AdaBoostBorderlineSMOTE-2: 0.156\n",
      "AdaBoostSMOTEENN: 0.141\n",
      "AdaBoostSMOTETomek: 0.152\n"
     ]
    }
   ],
   "source": [
    "for name,c in cm:\n",
    "    print(\"{}: {:.3f}\".format(name,c[1][1]/(c[1][1]+c[0][1]+c[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836eccca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
