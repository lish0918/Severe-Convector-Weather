{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0b4d40",
   "metadata": {},
   "source": [
    "# Imbalanced-learn for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae4c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,log_loss,auc,plot_confusion_matrix\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, label_binarize, OneHotEncoder, LabelEncoder)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import cycle, product\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379b367",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61508902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_excel('../Case.xlsx',sheet_name='initial')\n",
    "array_0=dataset.values\n",
    "\n",
    "array=[]\n",
    "for i in array_0:\n",
    "    if i[0]==1:\n",
    "        array.append(list(i))\n",
    "    data=np.array(array)\n",
    "\n",
    "X =data[:,1:18]\n",
    "Y =data[:,20]\n",
    "seed = random.randint(1,1000)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "train_set_dict = {}\n",
    "train_set_dict['RawData'] = (X_train,y_train)\n",
    "\n",
    "label_dict = {'Normal': 0,\n",
    "              'rain': 1,\n",
    "             'thunder': 2,\n",
    "             'wind': 3}\n",
    "labels = [key for i in sorted(label_dict.values()) for key,val in label_dict.items() if val==i]\n",
    "labels_number = sorted(label_dict.values()) # [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073b003",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362be73c",
   "metadata": {},
   "source": [
    "### RandomOverSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f88e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 179), (3.0, 179)]\n"
     ]
    }
   ],
   "source": [
    "# 简单的复制样本\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled ,y_resampled= ros.fit_resample(X_train,y_train)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['RandomOverSampler'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2156d3",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3803a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 179)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-1',k_neighbors=3).fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['BorderlineSMOTE-1'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa17fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 179)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE(kind='borderline-2',k_neighbors=3).fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['BorderlineSMOTE-2'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226b6ce",
   "metadata": {},
   "source": [
    "## Under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c478601",
   "metadata": {},
   "source": [
    "### ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1eaf4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 2), (2.0, 2), (3.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['ClusterCentroids'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb561f",
   "metadata": {},
   "source": [
    "### RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6101d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 2), (2.0, 2), (3.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['RandomUnderSampler'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f33a7",
   "metadata": {},
   "source": [
    "### EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da61ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 148), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "X_resampled, y_resampled = enn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['EditedNearestNeighbours'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f495b7",
   "metadata": {},
   "source": [
    "### RepeatedEditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8389e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 148), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "X_resampled, y_resampled = renn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['RepeatedEditedNearestNeighbours'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a9ac4",
   "metadata": {},
   "source": [
    "### AllKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697126c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 171), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "allknn = AllKNN()\n",
    "X_resampled, y_resampled = allknn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['AllKNN'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a88a39",
   "metadata": {},
   "source": [
    "### CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68597777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 14), (2.0, 2), (3.0, 4)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "cnn = CondensedNearestNeighbour(random_state=0)\n",
    "X_resampled, y_resampled = cnn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['CondensedNearestNeighbour'] = (X_resampled ,y_resampled)\n",
    "#slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9fd7d",
   "metadata": {},
   "source": [
    "### OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5185ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 42), (2.0, 2), (3.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "X_resampled, y_resampled = oss.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['OneSidedSelection'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d301379",
   "metadata": {},
   "source": [
    "### NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9513b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 173), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_resampled, y_resampled = ncr.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "train_set_dict['NeighbourhoodCleaningRule'] = (X_resampled ,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886163f2",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8263f",
   "metadata": {},
   "source": [
    "使用训练数据的不同随机子集来训练每个 Base Model，最后每个 Base Model 权重相同，分类问题进行投票，回归问题平均。\n",
    "\n",
    "随机森林就用到了Bagging，并且具有天然的并行性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4174384",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cde4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "train_set_dict['Bagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1cafe",
   "metadata": {},
   "source": [
    "### BalancedBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83acd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "train_set_dict['BalancedBagging'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0eccc9",
   "metadata": {},
   "source": [
    "### BalancedRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb391d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "train_set_dict['BalancedRandomForest'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d877f",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570aace",
   "metadata": {},
   "source": [
    "Boosting是一种迭代的方法，每一次训练会更关心上一次被分错的样本，比如改变被错分的样本的权重的Adaboost方法。还有许多都是基于这种思想，比如Gradient Boosting等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228148fa",
   "metadata": {},
   "source": [
    "### RUSBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffac187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "train_set_dict['RUSBoost'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99521d",
   "metadata": {},
   "source": [
    "### EasyEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c97941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 179), (2.0, 2), (3.0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))\n",
    "train_set_dict['EasyEnsemble'] = (X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26088094",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a9c131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5347855d8fe400f9e7d7eef717496b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "################### train #####################################\n",
    "plt.figure(figsize=(12, 6))\n",
    "cm = []\n",
    "clf_report_list = []\n",
    "for name, (X, y) in tqdm_notebook(list(train_set_dict.items())):\n",
    "    RANDOM_STATE = 2019\n",
    "    if name in ['Bagging']:\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                random_state=0)\n",
    "    elif name in ['BalancedBagging']:\n",
    "        from imblearn.ensemble import BalancedBaggingClassifier\n",
    "        clf = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                        sampling_strategy='auto',\n",
    "                                        replacement=False,\n",
    "                                        random_state=0)\n",
    "    elif name in ['BalancedRandomForest']:\n",
    "        from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "        clf = BalancedRandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    elif name in ['RUSBoost']:\n",
    "        from imblearn.ensemble import RUSBoostClassifier\n",
    "        clf = RUSBoostClassifier(random_state=0)\n",
    "    elif name in ['EasyEnsemble']:\n",
    "        from imblearn.ensemble import EasyEnsembleClassifier\n",
    "        clf = EasyEnsembleClassifier(random_state=0)\n",
    "    else:\n",
    "        # 模型\n",
    "        clf = RandomForestClassifier(n_estimators=161,\n",
    "                                     max_depth=49,\n",
    "                                     max_features=\"sqrt\",\n",
    "                                     random_state=RANDOM_STATE)\n",
    "    clf.fit(X, y)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_score = clf.predict_proba(X_test)  # valid score\n",
    "######################### 测试集评估 ########################\n",
    "\n",
    "    # 分类报告\n",
    "    clf_report = classification_report_imbalanced(\n",
    "        y_test, y_test_pred, digits=4, target_names=labels)\n",
    "    clf_report_list.append(clf_report)\n",
    "    # 混淆矩阵\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    cm.append((name, cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b20ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
